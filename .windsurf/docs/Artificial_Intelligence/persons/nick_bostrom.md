# Nick Bostrom (1973-Present)

## Overview
Nick Bostrom is a Swedish philosopher athe University of Oxford known for his work on existential risk, the anthropic principle, and superintelligence. He is a Professor at Oxford University and the founding director of the [Future of Humanity Institute](https://www.fhi.ox.ac.uk/). Bostrom's work has been influential in shaping discussions around artificial general intelligence (AGI) safety and the long-term future of humanity.

## Related Figures
- [Demis Hassabis](/ai/persons/demis_hassabis.md) - DeepMind's work on AGIntersects with Bostrom'safety research
- [Yann LeCun](/ai/persons/yann_lecun.md) - Different perspectives on AI risk andevelopmentimelines
- [Elon Musk](/ai/persons/elon_musk.md) - Co-founded OpenAI with shared concerns about AI safety
- [Stuart Russell](/ai/persons/stuart_russell.md) - Fellow AI safety researcher and author of "Human Compatible"

## Key Contributions
- Superintelligence: Paths, Dangers, Strategies (2014)
- Anthropic Bias (2002)
- Global Catastrophic Risks (2008)
- Simulation Hypothesis

## Biography
Born in Helsingborg, Sweden, Bostrom received his PhD in philosophy from the London School of Economics. He has held academic positions at Yale University and the University of Oxford. His work spans philosophy, artificial intelligence, and ethics, with a focus on the long-term implications of technology.

## Major Works
### Superintelligence: Paths, Dangers, Strategies (2014)
- **Impact**: Brought mainstream attention to the risks of artificial general intelligence
- **Key Concepts**: Intelligencexplosion, control problem, instrumental convergence
- **Reception**: Widely praised for its rigorous analysis of AI safety issues

## Publications
- "Are You Living in a Computer Simulation?" (2003) - Philosophical Quarterly
- "Existential Risks: Analyzing Human Extinction Scenarios" (2002) - Journal of Evolution and Technology
- "The Future of Human Evolution" (2004) - Science and Ultimate Reality

## Awards and Honors
- Eugene R. Gannon Award (2009)
- FP Top 100 Global Thinkers (2009, 2014, 2015)
- Prospect's World Thinkers (2014)

## Current Work
- Professor, Oxford University
- Director, Future of Humanity Institute
- Research focuses on AI safety, existential risk, and global priorities

## Mediappearances
- TED Talk: "What happens when our computers get smarter than we are?" (2015)
- Lex Fridman Podcast #90 (2019)
- The Joe Rogan Experience #1155 (2018)

## Furthereading
- [Personal Website](https://nickbostrom.com/) - Complete bibliography and papers
- [Google Scholar](https://scholar.google.com/citations?user=6XjQH5cAAAAJ) - Academic publications and citations
- [Future of Humanity Institute](https://www.fhi.ox.ac.uk/) - Research center founded by Bostrom
- [80000 Hours Podcast](https://80000hours.org/podcast/episodes/nick-bostrom-perspective-on-ai/) - In-depth interview on AI and long-term thinking

## In Calibre
[Link to Nick Bostrom's works in Calibre Web]

## See Also
- [AI Safety Research](https://futureoflife.org/ai-safety-research/)
- [Effective Altruism](https://www.effectivealtruism.org/)
- [Machine Intelligence Research Institute](https://intelligence.org/)

